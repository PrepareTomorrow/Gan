{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic GAN 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "- [Generative Adversarial Networks](https://arxiv.org/abs/1406.2661)\n",
    "- [NIPS 2016 Tutorial:\n",
    "Generative Adversarial Networks](https://arxiv.org/pdf/1701.00160.pdf)\n",
    "- [image source](https://xiaohongliu.ca/post/gan/)\n",
    "![gan2-2.PNG](attachment:gan2-2.PNG)\n",
    "## Library\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "import numpy as np\n",
    "import math\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "## Hyperparameters\n",
    "\"\"\"\n",
    "학습에 사용될 hyperparameter 값들을 넣을 class를 정의합니다.\n",
    "\"\"\"\n",
    "class AttrDict(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(AttrDict, self).__init__(*args, **kwargs)\n",
    "        self.__dict__ = self\n",
    "\"\"\"\n",
    "GAN model 학습에 사용되는 결과 이미지 저장 경로, 에포크 수, 모델 입력 이미지 크기 등을 정의합니다.\n",
    "\"\"\"\n",
    "config = AttrDict()\n",
    "config.data_path = 'data/'\n",
    "config.save_path = 'save/'\n",
    "config.dataset = 'CIFAR10' #CIFAR10\n",
    "config.n_epoch = 500\n",
    "config.log_interval = 100\n",
    "config.save_interval = 20\n",
    "config.batch_size = 64\n",
    "config.learning_rate = 0.0002\n",
    "config.b1 = 0.5\n",
    "config.b2 = 0.999\n",
    "config.img_shape = (3, 32, 32)\n",
    "config.latent_size = 100\n",
    "\"\"\"\n",
    "모델 입력 이미지에 수행할 normalization과 모델 생성 결과 이미지에 수행할 denormalization을 정의합니다.\n",
    "\"\"\"\n",
    "config.augmentation = transforms.Compose([\n",
    "                        transforms.Resize((config.img_shape[1], config.img_shape[2])),\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize(mean=[0.5], std=[0.5]) \n",
    "                      ])\n",
    "config.denormalize = lambda x: x*0.5+0.5\n",
    "config.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if not os.path.isdir(config.data_path):\n",
    "    os.makedirs(config.data_path)\n",
    "if not os.path.isdir(os.path.join(config.save_path, config.dataset)):\n",
    "    os.makedirs(os.path.join(config.save_path, config.dataset))\n",
    "config.device\n",
    "## Data load\n",
    "\"\"\"\n",
    "MNIST와 CIFAR-10은 torchvision 라이브러리에서 제공하여 아래와 같이 사용할 수 있습니다.\n",
    "\"\"\"\n",
    "if config.dataset == 'MNIST':\n",
    "    train_dataset = datasets.MNIST(config.data_path,\n",
    "                                    train=True,\n",
    "                                    download=True,\n",
    "                                    transform=config.augmentation\n",
    "                                  ) \n",
    "elif config.dataset == 'CIFAR10': \n",
    "    train_dataset = datasets.CIFAR10(config.data_path,\n",
    "                                       train=True,\n",
    "                                       download=True,\n",
    "                                       transform=config.augmentation\n",
    "                                     )\n",
    "\"\"\"\n",
    "training set을 Dataloader에 넣습니다. \n",
    "\"\"\"\n",
    "train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "print(train_dataset)\n",
    "## GAN model\n",
    "\"\"\"\n",
    " 일반적으로, GAN에서는 loss가 Discriminator에서부터 Generator로 흐를 때 생길 수 있는 \n",
    " vanishing gradient 현상을 완화하기 위해 Leaky ReLU를 많이 사용합니다. \n",
    "\"\"\"\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *self.block(config.latent_size, 128, batchnorm=False),\n",
    "            *self.block(128, 256),\n",
    "            *self.block(256, 512),\n",
    "            *self.block(512, 1024),\n",
    "            nn.Linear(1024, int(np.prod(config.img_shape))),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.reshape(img.shape[0], *config.img_shape)\n",
    "        return img\n",
    "    \n",
    "    def block(self, input_size, output_size, batchnorm=True):\n",
    "        layers = [nn.Linear(input_size, output_size)]\n",
    "        if batchnorm:\n",
    "            layers.append(nn.BatchNorm1d(output_size))\n",
    "        layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "        return layers\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(int(np.prod(config.img_shape)), 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        img = img.reshape(img.shape[0], -1)\n",
    "        validity = self.model(img)\n",
    "        return validity\n",
    "#### Binary Cross Entropy loss between the target and the input probabilities\n",
    "- [torch.nn.BCELoss](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html)\n",
    "![bceloss.PNG](attachment:bceloss.PNG)\n",
    "\"\"\"\n",
    "binary cross entropy loss를 사용하여 adversarial loss를 구현합니다.\n",
    "\"\"\"\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "\"\"\"\n",
    "Generator와 Discriminator를 각각 정의하고, 상응하는 optimizer도 함께 정의합니다.\n",
    "\"\"\"\n",
    "generator = Generator(config).to(config.device)\n",
    "discriminator = Discriminator(config).to(config.device)\n",
    "\n",
    "optimizer_g = torch.optim.Adam(generator.parameters(), lr=config.learning_rate, betas=(config.b1, config.b2))\n",
    "optimizer_d = torch.optim.Adam(discriminator.parameters(), lr=config.learning_rate, betas=(config.b1, config.b2))\n",
    "generator.model\n",
    "discriminator.model\n",
    "## Training\n",
    "\"\"\"\n",
    "Generator와 Discriminator를 번갈아 학습합니다.\n",
    "\"\"\"\n",
    "g_loss_list = []\n",
    "d_loss_list = []\n",
    "for epoch in tqdm(range(config.n_epoch)):\n",
    "    for i, (real_img, _) in enumerate(train_loader):\n",
    "        \n",
    "        real_img = real_img.to(config.device)\n",
    "\n",
    "        \"\"\"\n",
    "        adversarial loss에 사용될 ground truth들입니다.\n",
    "        Discriminator에게 있어 실제 이미지는 1, generator가 생성한 fake 이미지는 0을 label로 합니다.\n",
    "        반대로 Generator는 자신이 생성한 fake 이미지의 label이 1이 되게 하여 Discriminator를 fooling 합니다.\n",
    "        \"\"\"\n",
    "        valid_label = torch.ones((real_img.shape[0], 1), device=config.device, dtype=torch.float32)\n",
    "        fake_label = torch.zeros((real_img.shape[0], 1), device=config.device, dtype=torch.float32)\n",
    "        \n",
    "        # ====================================================#\n",
    "        #                Train Discriminator                  #\n",
    "        # ====================================================#\n",
    "\n",
    "        \"\"\"\n",
    "        Gaussian random noise를 Generator에게 입력하여 fake 이미지들을 생성합니다.\n",
    "        \"\"\"\n",
    "        z = torch.randn((real_img.shape[0], config.latent_size), device=config.device, dtype=torch.float32)\n",
    "        gen_img = generator(z)\n",
    "\n",
    "        \"\"\"\n",
    "        Discriminator가 실제 이미지와 Generator가 생성한 이미지를 잘 구별하는지 loss를 계산합니다.\n",
    "        이 때, Generator는 현재 계산된 loss로 학습되지 않으므로, \n",
    "        detach() 함수를 이용하여 생성 이미지를 computation graph에서 분리한 후 Discriminator의 입력으로 넣어줍니다. \n",
    "        \"\"\"\n",
    "        real_loss = criterion(discriminator(real_img), valid_label)\n",
    "        fake_loss = criterion(discriminator(gen_img.detach()), fake_label)\n",
    "        d_loss = (real_loss + fake_loss) * 0.5\n",
    "        \n",
    "        \"\"\"\n",
    "        Discriminator를 업데이트합니다.\n",
    "        \"\"\"\n",
    "        optimizer_d.zero_grad()\n",
    "        d_loss.backward()\n",
    "        optimizer_d.step()\n",
    "\n",
    "        # ====================================================#\n",
    "        #                   Train Generator                   #\n",
    "        # ====================================================#\n",
    "\n",
    "        \"\"\"\n",
    "        Gaussian random noise를 Generator에게 입력하여 fake 이미지들을 생성합니다.\n",
    "        \"\"\"\n",
    "        z = torch.randn((real_img.shape[0], config.latent_size), device=config.device, dtype=torch.float32)\n",
    "        gen_img = generator(z)\n",
    "\n",
    "        \"\"\"\n",
    "        Generator가 Discriminator를 속일 수 있는지 loss를 계산합니다.\n",
    "        \"\"\"\n",
    "        g_loss = criterion(discriminator(gen_img), valid_label)\n",
    "        \n",
    "        \"\"\"\n",
    "        Generator를 업데이트합니다.\n",
    "        \"\"\"\n",
    "        optimizer_g.zero_grad()\n",
    "        g_loss.backward()\n",
    "        optimizer_g.step()\n",
    "\n",
    "        if (i+1) % config.log_interval == 0:\n",
    "            g_loss_list.append(g_loss.item())\n",
    "            d_loss_list.append(d_loss.item())\n",
    "            print('Epoch [{}/{}] Batch [{}/{}] Discriminator loss: {:.4f} Generator loss: {:.4f}'.format(\n",
    "                epoch+1, config.n_epoch, i+1, len(train_loader), d_loss.item(), g_loss.item()))\n",
    "\n",
    "    if (epoch+1) % config.save_interval == 0:\n",
    "        save_path = os.path.join(config.save_path, config.dataset, 'epoch_[{}].png'.format(epoch+1))\n",
    "        gen_img = config.denormalize(gen_img)\n",
    "        torchvision.utils.save_image(gen_img.data[:25], save_path, nrow=5, normalize=True)\n",
    "plt.title('GAN training loss on {} data'.format(config.dataset))\n",
    "plt.plot(g_loss_list, label='generator loss')\n",
    "plt.plot(d_loss_list, label='discriminator loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "## Qualitative results\n",
    "save_path = os.path.join(config.save_path, config.dataset)\n",
    "for image_path in os.listdir(save_path):\n",
    "    if image_path.endswith('.png'):\n",
    "        plt.figure(figsize=(5,5))\n",
    "        image = Image.open(os.path.join(save_path, image_path))\n",
    "        plt.title(image_path)\n",
    "        plt.imshow(image)\n",
    "        plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
