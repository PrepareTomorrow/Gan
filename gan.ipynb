{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic GAN 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tqdm\n",
    "#!conda install pytorch torchvision torchaudio cudatoolkit=11.1 -c pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Generative Adversarial Networks](https://arxiv.org/abs/1406.2661)\n",
    "- [NIPS 2016 Tutorial:\n",
    "Generative Adversarial Networks](https://arxiv.org/pdf/1701.00160.pdf)\n",
    "- [image source](https://xiaohongliu.ca/post/gan/)\n",
    "![gan2-2.PNG](attachment:gan2-2.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "import numpy as np\n",
    "import math\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "학습에 사용될 hyperparameter 값들을 넣을 class를 정의합니다.\n",
    "\"\"\"\n",
    "class AttrDict(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(AttrDict, self).__init__(*args, **kwargs)\n",
    "        self.__dict__ = self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "GAN model 학습에 사용되는 결과 이미지 저장 경로, 에포크 수, 모델 입력 이미지 크기 등을 정의합니다.\n",
    "\"\"\"\n",
    "config = AttrDict()\n",
    "config.data_path = 'data/'\n",
    "config.save_path = 'save/'\n",
    "config.dataset = 'CIFAR10' #CIFAR10\n",
    "config.n_epoch = 500\n",
    "config.log_interval = 100\n",
    "config.save_interval = 20\n",
    "config.batch_size = 64\n",
    "config.learning_rate = 0.0002\n",
    "config.b1 = 0.5\n",
    "config.b2 = 0.999\n",
    "config.img_shape = (3, 32, 32)\n",
    "config.latent_size = 100\n",
    "\"\"\"\n",
    "모델 입력 이미지에 수행할 normalization과 모델 생성 결과 이미지에 수행할 denormalization을 정의합니다.\n",
    "\"\"\"\n",
    "config.augmentation = transforms.Compose([\n",
    "                        transforms.Resize((config.img_shape[1], config.img_shape[2])),\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize(mean=[0.5], std=[0.5]) \n",
    "                      ])\n",
    "config.denormalize = lambda x: x*0.5+0.5\n",
    "config.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(config.data_path):\n",
    "    os.makedirs(config.data_path)\n",
    "if not os.path.isdir(os.path.join(config.save_path, config.dataset)):\n",
    "    os.makedirs(os.path.join(config.save_path, config.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#torch.cuda.current_device()\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]\n",
    "#torch.cuda_path\n",
    "torch.cuda.is_available()\n",
    "#torch.cuda_version\n",
    "#torch.cuda.get_device_name(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Dataset CIFAR10\n",
      "    Number of datapoints: 50000\n",
      "    Root location: data/\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=None)\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.5], std=[0.5])\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "MNIST와 CIFAR-10은 torchvision 라이브러리에서 제공하여 아래와 같이 사용할 수 있습니다.\n",
    "\"\"\"\n",
    "if config.dataset == 'MNIST':\n",
    "    train_dataset = datasets.MNIST(config.data_path,\n",
    "                                    train=True,\n",
    "                                    download=True,\n",
    "                                    transform=config.augmentation\n",
    "                                  ) \n",
    "elif config.dataset == 'CIFAR10': \n",
    "    train_dataset = datasets.CIFAR10(config.data_path,\n",
    "                                       train=True,\n",
    "                                       download=True,\n",
    "                                       transform=config.augmentation\n",
    "                                     )\n",
    "\"\"\"\n",
    "training set을 Dataloader에 넣습니다. \n",
    "\"\"\"\n",
    "train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GAN model\n",
    "\"\"\"\n",
    " 일반적으로, GAN에서는 loss가 Discriminator에서부터 Generator로 흐를 때 생길 수 있는 \n",
    " vanishing gradient 현상을 완화하기 위해 Leaky ReLU를 많이 사용합니다. \n",
    "\"\"\"\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *self.block(config.latent_size, 128, batchnorm=False),\n",
    "            *self.block(128, 256),\n",
    "            *self.block(256, 512),\n",
    "            *self.block(512, 1024),\n",
    "            nn.Linear(1024, int(np.prod(config.img_shape))),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.reshape(img.shape[0], *config.img_shape)\n",
    "        return img\n",
    "    \n",
    "    def block(self, input_size, output_size, batchnorm=True):\n",
    "        layers = [nn.Linear(input_size, output_size)]\n",
    "        if batchnorm:\n",
    "            layers.append(nn.BatchNorm1d(output_size))\n",
    "        layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "        return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(int(np.prod(config.img_shape)), 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        img = img.reshape(img.shape[0], -1)\n",
    "        validity = self.model(img)\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary Cross Entropy loss between the target and the input probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [torch.nn.BCELoss](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![bceloss.PNG](attachment:bceloss.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "binary cross entropy loss를 사용하여 adversarial loss를 구현합니다.\n",
    "\"\"\"\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "\"\"\"\n",
    "Generator와 Discriminator를 각각 정의하고, 상응하는 optimizer도 함께 정의합니다.\n",
    "\"\"\"\n",
    "generator = Generator(config).to(config.device)\n",
    "discriminator = Discriminator(config).to(config.device)\n",
    "\n",
    "optimizer_g = torch.optim.Adam(generator.parameters(), lr=config.learning_rate, betas=(config.b1, config.b2))\n",
    "optimizer_d = torch.optim.Adam(discriminator.parameters(), lr=config.learning_rate, betas=(config.b1, config.b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=100, out_features=128, bias=True)\n",
       "  (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "  (2): Linear(in_features=128, out_features=256, bias=True)\n",
       "  (3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "  (5): Linear(in_features=256, out_features=512, bias=True)\n",
       "  (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "  (8): Linear(in_features=512, out_features=1024, bias=True)\n",
       "  (9): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "  (11): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "  (12): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=3072, out_features=512, bias=True)\n",
       "  (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "  (2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "  (4): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (5): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39ec758cc1c5456da6b4ef665a48d9a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500] Batch [100/782] Discriminator loss: 0.5566 Generator loss: 2.0546\n",
      "Epoch [1/500] Batch [200/782] Discriminator loss: 0.5239 Generator loss: 1.8828\n",
      "Epoch [1/500] Batch [300/782] Discriminator loss: 0.5901 Generator loss: 3.5278\n",
      "Epoch [1/500] Batch [400/782] Discriminator loss: 0.6246 Generator loss: 1.7305\n",
      "Epoch [1/500] Batch [500/782] Discriminator loss: 0.6203 Generator loss: 1.8179\n",
      "Epoch [1/500] Batch [600/782] Discriminator loss: 0.4953 Generator loss: 1.7541\n",
      "Epoch [1/500] Batch [700/782] Discriminator loss: 0.5203 Generator loss: 1.8410\n",
      "Epoch [2/500] Batch [100/782] Discriminator loss: 0.5517 Generator loss: 1.4788\n",
      "Epoch [2/500] Batch [200/782] Discriminator loss: 0.5170 Generator loss: 1.5574\n",
      "Epoch [2/500] Batch [300/782] Discriminator loss: 0.5358 Generator loss: 1.6666\n",
      "Epoch [2/500] Batch [400/782] Discriminator loss: 0.5571 Generator loss: 1.4617\n",
      "Epoch [2/500] Batch [500/782] Discriminator loss: 0.5221 Generator loss: 1.3792\n",
      "Epoch [2/500] Batch [600/782] Discriminator loss: 0.6265 Generator loss: 1.6032\n",
      "Epoch [2/500] Batch [700/782] Discriminator loss: 0.5369 Generator loss: 1.2959\n",
      "Epoch [3/500] Batch [100/782] Discriminator loss: 0.5809 Generator loss: 1.2793\n",
      "Epoch [3/500] Batch [200/782] Discriminator loss: 0.6456 Generator loss: 1.3487\n",
      "Epoch [3/500] Batch [300/782] Discriminator loss: 0.6435 Generator loss: 1.3037\n",
      "Epoch [3/500] Batch [400/782] Discriminator loss: 0.5797 Generator loss: 1.4827\n",
      "Epoch [3/500] Batch [500/782] Discriminator loss: 0.5600 Generator loss: 1.2363\n",
      "Epoch [3/500] Batch [600/782] Discriminator loss: 0.6372 Generator loss: 1.2572\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Generator와 Discriminator를 번갈아 학습합니다.\n",
    "\"\"\"\n",
    "g_loss_list = []\n",
    "d_loss_list = []\n",
    "for epoch in tqdm(range(config.n_epoch)):\n",
    "    for i, (real_img, _) in enumerate(train_loader):\n",
    "        \n",
    "        real_img = real_img.to(config.device)\n",
    "\n",
    "        \"\"\"\n",
    "        adversarial loss에 사용될 ground truth들입니다.\n",
    "        Discriminator에게 있어 실제 이미지는 1, generator가 생성한 fake 이미지는 0을 label로 합니다.\n",
    "        반대로 Generator는 자신이 생성한 fake 이미지의 label이 1이 되게 하여 Discriminator를 fooling 합니다.\n",
    "        \"\"\"\n",
    "        valid_label = torch.ones((real_img.shape[0], 1), device=config.device, dtype=torch.float32)\n",
    "        fake_label = torch.zeros((real_img.shape[0], 1), device=config.device, dtype=torch.float32)\n",
    "        \n",
    "        # ====================================================#\n",
    "        #                Train Discriminator                  #\n",
    "        # ====================================================#\n",
    "\n",
    "        \"\"\"\n",
    "        Gaussian random noise를 Generator에게 입력하여 fake 이미지들을 생성합니다.\n",
    "        \"\"\"\n",
    "        z = torch.randn((real_img.shape[0], config.latent_size), device=config.device, dtype=torch.float32)\n",
    "        gen_img = generator(z)\n",
    "\n",
    "        \"\"\"\n",
    "        Discriminator가 실제 이미지와 Generator가 생성한 이미지를 잘 구별하는지 loss를 계산합니다.\n",
    "        이 때, Generator는 현재 계산된 loss로 학습되지 않으므로, \n",
    "        detach() 함수를 이용하여 생성 이미지를 computation graph에서 분리한 후 Discriminator의 입력으로 넣어줍니다. \n",
    "        \"\"\"\n",
    "        real_loss = criterion(discriminator(real_img), valid_label)\n",
    "        fake_loss = criterion(discriminator(gen_img.detach()), fake_label)\n",
    "        d_loss = (real_loss + fake_loss) * 0.5\n",
    "        \n",
    "        \"\"\"\n",
    "        Discriminator를 업데이트합니다.\n",
    "        \"\"\"\n",
    "        optimizer_d.zero_grad()\n",
    "        d_loss.backward()\n",
    "        optimizer_d.step()\n",
    "\n",
    "        # ====================================================#\n",
    "        #                   Train Generator                   #\n",
    "        # ====================================================#\n",
    "\n",
    "        \"\"\"\n",
    "        Gaussian random noise를 Generator에게 입력하여 fake 이미지들을 생성합니다.\n",
    "        \"\"\"\n",
    "        z = torch.randn((real_img.shape[0], config.latent_size), device=config.device, dtype=torch.float32)\n",
    "        gen_img = generator(z)\n",
    "\n",
    "        \"\"\"\n",
    "        Generator가 Discriminator를 속일 수 있는지 loss를 계산합니다.\n",
    "        \"\"\"\n",
    "        g_loss = criterion(discriminator(gen_img), valid_label)\n",
    "        \n",
    "        \"\"\"\n",
    "        Generator를 업데이트합니다.\n",
    "        \"\"\"\n",
    "        optimizer_g.zero_grad()\n",
    "        g_loss.backward()\n",
    "        optimizer_g.step()\n",
    "\n",
    "        if (i+1) % config.log_interval == 0:\n",
    "            g_loss_list.append(g_loss.item())\n",
    "            d_loss_list.append(d_loss.item())\n",
    "            print('Epoch [{}/{}] Batch [{}/{}] Discriminator loss: {:.4f} Generator loss: {:.4f}'.format(\n",
    "                epoch+1, config.n_epoch, i+1, len(train_loader), d_loss.item(), g_loss.item()))\n",
    "\n",
    "    if (epoch+1) % config.save_interval == 0:\n",
    "        save_path = os.path.join(config.save_path, config.dataset, 'epoch_[{}].png'.format(epoch+1))\n",
    "        gen_img = config.denormalize(gen_img)\n",
    "        torchvision.utils.save_image(gen_img.data[:25], save_path, nrow=5, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3227398701.py, line 48)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\fishd\\AppData\\Local\\Temp\\ipykernel_10780\\3227398701.py\"\u001b[1;36m, line \u001b[1;32m48\u001b[0m\n\u001b[1;33m    - [torch.nn.BCELoss](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html)\u001b[0m\n\u001b[1;37m                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "plt.title('GAN training loss on {} data'.format(config.dataset))\n",
    "plt.plot(g_loss_list, label='generator loss')\n",
    "plt.plot(d_loss_list, label='discriminator loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "## Qualitative results\n",
    "save_path = os.path.join(config.save_path, config.dataset)\n",
    "for image_path in os.listdir(save_path):\n",
    "    if image_path.endswith('.png'):\n",
    "        plt.figure(figsize=(5,5))\n",
    "        image = Image.open(os.path.join(save_path, image_path))\n",
    "        plt.title(image_path)\n",
    "        plt.imshow(image)\n",
    "        plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7940d0d72e881cb11dd568ba28aec900f56fa18be17fd320ef03619339573588"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('normal')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
